# 1ï¸âƒ£ One-Page ML Mental Map (The Whole Game)

Think of ML as **5 connected layers**.
If one layer is weak â†’ accuracy dies.

```
Business Goal
     â†“
Problem Definition
     â†“
Data Reality Check
     â†“
Modeling Strategy
     â†“
Evaluation & Error Analysis
```

### ğŸ§  Layer 1: Business Goal

* What decision will be taken?
* Cost of false prediction?
* Metric that represents success?

> No metric = no model.

---

### ğŸ§  Layer 2: Problem Definition

* Target type?

  * Continuous â†’ Regression
  * Discrete â†’ Classification
  * No target â†’ Clustering
  * Time dependent â†’ Forecasting
* Single prediction or sequence?
* Real-time or batch?

---

### ğŸ§  Layer 3: Data Reality Check

* Data size (rows & features)
* Missing values
* Noise & outliers
* Leakage risk
* Class imbalance

> Bad data beats bad models every time.

---

### ğŸ§  Layer 4: Modeling Strategy

* Baseline first
* Simple model â†’ complex model
* Regularization before tuning
* Cross-validation
* Feature importance

---

### ğŸ§  Layer 5: Evaluation & Error Analysis

* Metric vs business goal
* Overfitting check
* Segment-level errors
* Stability across folds

> A model without error analysis is unfinished.

---

# 2ï¸âƒ£ ML TYPEâ€“BASED CHECKLISTS (What to check + Statistical tests)

Now the **real value**.

---

## ğŸ”¹ A) REGRESSION MODELS (Continuous Target)

### Step-by-Step Checklist

### 1ï¸âƒ£ Target Analysis

Check:

* Distribution (histogram)
* Skewness
* Outliers
* Zero / negative values

Statistical tests:

* **Shapiro-Wilk** â†’ normality (small data)
* **Kolmogorovâ€“Smirnov** â†’ large data
* **Boxplot / IQR** â†’ outliers

If skewed â†’ consider:

* log
* Box-Cox
* Yeo-Johnson

---

### 2ï¸âƒ£ Feature Analysis

Numeric features:

* Correlation with target (Pearson / Spearman)
* Multicollinearity

Tests:

* **Pearson** â†’ linear relation
* **Spearman** â†’ monotonic relation
* **VIF** â†’ multicollinearity

Categorical features:

* Group mean comparison

Tests:

* **ANOVA** â†’ category vs numeric target
* **Kruskalâ€“Wallis** â†’ non-normal target

---

### 3ï¸âƒ£ Assumption Checks (for linear models)

* Linearity
* Homoscedasticity
* Normal residuals
* Independence

Tests:

* **Breuschâ€“Pagan** â†’ heteroscedasticity
* **Durbinâ€“Watson** â†’ autocorrelation

---

### 4ï¸âƒ£ Metrics

* MAE â†’ business-friendly
* RMSE â†’ penalizes large errors
* RÂ² â†’ explanation, not accuracy

---

### 5ï¸âƒ£ Error Analysis

Check:

* Residuals vs predictions
* Error by segment
* Extreme error cases

---

## ğŸ”¹ B) CLASSIFICATION MODELS (Categorical Target)

### Step-by-Step Checklist

---

### 1ï¸âƒ£ Target Analysis

Check:

* Class balance
* Minority class importance

Tests:

* **Chi-square goodness-of-fit** â†’ imbalance awareness

Rule:

* Imbalanced data â‰  accuracy metric

---

### 2ï¸âƒ£ Feature vs Target

Numeric:

* Distribution per class

Tests:

* **t-test** â†’ binary class
* **Mannâ€“Whitney U** â†’ non-normal
* **ANOVA** â†’ multi-class

Categorical:

* Relationship with target

Tests:

* **Chi-square test of independence**
* **Fisherâ€™s Exact** (small samples)

---

### 3ï¸âƒ£ Encoding & Scaling

* One-hot for low cardinality
* Target / frequency encoding for high cardinality
* Scaling needed for:

  * Logistic Regression
  * SVM
  * KNN

---

### 4ï¸âƒ£ Metrics (DO NOT USE ACCURACY BLINDLY)

* Precision
* Recall
* F1-score
* ROC-AUC
* PR-AUC (imbalanced)

Choose metric based on:

* False Positive cost
* False Negative cost

---

### 5ï¸âƒ£ Threshold & Error Analysis

Check:

* Confusion matrix
* Wrong predictions per class
* Threshold tuning

---

## ğŸ”¹ C) CLUSTERING (No Target)

### Checklist

1. Feature scaling (mandatory)
2. Distance metric choice
3. Number of clusters

Tests / Methods:

* **Elbow method**
* **Silhouette score**
* **Daviesâ€“Bouldin index**

Validation:

* Cluster interpretability
* Business meaning

---

## ğŸ”¹ D) TIME SERIES FORECASTING

### Checklist

1. Trend
2. Seasonality
3. Stationarity

Tests:

* **ADF Test** â†’ stationarity
* **KPSS** â†’ trend stationarity
* **ACF / PACF** â†’ lag selection

Rules:

* NEVER random split
* Always time-based split

---

## ğŸ”¹ E) FEATURE SELECTION (ALL TYPES)

Methods:

* Correlation filtering
* Mutual information
* Recursive Feature Elimination
* Model-based importance
