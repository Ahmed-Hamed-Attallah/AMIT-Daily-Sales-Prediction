# MASTER DECISION GUIDE

## (What to use, when to use it, and what error it fixes)

---

# 1ï¸âƒ£ TARGET VARIABLE â€” WHAT TO DO & WHEN

## ğŸ”¹ Regression Target

### ğŸ”¸ Problem: Target is **skewed**

**Use when**

* Histogram is long-tailed
* RMSE >> MAE

**Do**

* `log(y + 1)`
* Yeo-Johnson (if zeros / negatives exist)

**Fixes**

* Large error domination
* Poor convergence
* Over-penalization of outliers

---

### ğŸ”¸ Problem: Extreme outliers

**Use when**

* Boxplot shows long whiskers
* Business says values are â€œrare but realâ€

**Do NOT**

* Blindly delete

**Do**

* Winsorization
* Robust models (Huber, Quantile Regression)
* Use MAE instead of RMSE

---

## ğŸ”¹ Classification Target

### ğŸ”¸ Problem: Class imbalance

**Use when**

* Minority < 20%
* Accuracy looks high but recall is bad

**Do**

* Change metric (F1 / Recall / PR-AUC)
* Class weights
* SMOTE (only on train set)

**Do NOT**

* Oversample test set

---

# 2ï¸âƒ£ FEATURE TYPE â€” WHAT TO USE & WHEN

---

## ğŸ”¹ Numeric Features

### ğŸ”¸ Problem: Non-linear relationship with target

**Use when**

* Scatter plot is curved
* Pearson â‰ˆ 0 but model still improves

**Do**

* Tree-based models
* Polynomial features
* Log / sqrt transforms

**Avoid**

* Linear regression without transformation

---

### ğŸ”¸ Problem: Strong multicollinearity

**Use when**

* VIF > 5
* Correlation > 0.85

**Do**

* Drop one feature
* Ridge / ElasticNet
* PCA (only if interpretability not needed)

**Avoid**

* Lasso alone (unstable selection)

---

## ğŸ”¹ Categorical Features

### ğŸ”¸ Problem: Low cardinality (â‰¤10)

**Use**

* One-hot encoding

**Avoid**

* Label encoding (adds fake order)

---

### ğŸ”¸ Problem: High cardinality (>20)

**Use when**

* Many unique values (city, product)

**Do**

* Target encoding
* Frequency encoding
* Group rare categories

**Avoid**

* One-hot â†’ dimensional explosion

---

# 3ï¸âƒ£ STATISTICAL TESTS â€” WHEN TO USE WHICH

---

## ğŸ”¹ Normality Tests

| Situation         | Use          |
| ----------------- | ------------ |
| Small data (<500) | Shapiro-Wilk |
| Large data        | KS test      |
| Visual check      | Q-Q plot     |

âš ï¸ Rule:
Normality matters **only** for:

* Linear regression assumptions
* Parametric tests

---

## ğŸ”¹ Numeric vs Numeric

| Relationship | Use                |
| ------------ | ------------------ |
| Linear       | Pearson            |
| Monotonic    | Spearman           |
| Non-linear   | Mutual Information |

---

## ğŸ”¹ Categorical vs Numeric

| Data condition | Test                  |
| -------------- | --------------------- |
| Normal target  | ANOVA                 |
| Non-normal     | Kruskalâ€“Wallis        |
| Binary target  | t-test / Mannâ€“Whitney |

---

## ğŸ”¹ Categorical vs Categorical

| Condition    | Test         |
| ------------ | ------------ |
| Large sample | Chi-square   |
| Small counts | Fisher Exact |

---

# 4ï¸âƒ£ MODEL SELECTION â€” WHEN TO USE WHAT

---

## ğŸ”¹ Linear Models

**Use when**

* Interpretability matters
* Relationship roughly linear
* Low data size

**Avoid when**

* Strong interactions
* Non-linearity

---

## ğŸ”¹ Tree-Based Models

**Use when**

* Non-linear data
* Mixed feature types
* Feature interactions exist

**Watch for**

* Overfitting â†’ limit depth, min_samples

---

## ğŸ”¹ Boosting Models

**Use when**

* Tabular data
* Mediumâ€“large dataset
* You want performance over interpretability

**Avoid**

* Dirty data
* Severe leakage

---

# 5ï¸âƒ£ SCALING â€” WHEN NEEDED, WHEN NOT

| Model             | Scaling |
| ----------------- | ------- |
| Linear / Logistic | YES     |
| SVM / KNN         | YES     |
| Tree-based        | NO      |
| Neural Networks   | YES     |

---

# 6ï¸âƒ£ TRAINâ€“TEST SPLIT â€” CRITICAL DECISIONS

---

## ğŸ”¹ Time dependency exists?

**Use**

* Time-based split

**Never**

* Random split

---

## ğŸ”¹ Small dataset?

**Use**

* Cross-validation (5â€“10 folds)

---

# 7ï¸âƒ£ OVERFITTING â€” HOW TO DETECT & FIX

### Detect

* Train >> Test metric
* CV variance high

### Fix

* Reduce model complexity
* Regularization
* More data
* Feature pruning

---

# 8ï¸âƒ£ ERROR ANALYSIS â€” WHEN & HOW

### When to do

* Always after first model

### How

* Plot residuals
* Analyze worst 5% errors
* Segment errors by feature

**If error is systematic â†’ feature problem**
**If error is random â†’ model limit**

---

# 9ï¸âƒ£ FINAL DECISION RULE (MEMORIZE THIS)

> **Data problem â†’ Feature fix â†’ Model choice â†’ Metric alignment**

Never reverse this order.

---
